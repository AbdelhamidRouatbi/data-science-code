{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7c24f9",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07a9e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "import joblib, pandas as pd, numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
    ")\n",
    "# -------- paths / config\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a1ab9",
   "metadata": {},
   "source": [
    "# Evaluate Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a7c6f",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Models on Regular season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "581a8963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline LR models on TEST ===\n",
      "lr-distance  AUC=0.6973  PR-AUC=0.1833  Brier=0.0853  LogLoss=0.3055  time=0.002s\n",
      "lr-angle     AUC=0.5555  PR-AUC=0.1227  Brier=0.0887  LogLoss=0.3208  time=0.002s\n",
      "lr-both      AUC=0.7126  PR-AUC=0.1925  Brier=0.0845  LogLoss=0.3015  time=0.002s\n",
      "\n",
      "figs written to: C:\\Users\\Gazal\\Documents\\Masters_Fall_2025\\Studies\\IFT 6758\\Projects\\Project_1 NHL\\Milestone_2\\data-science-code\\milestone2\\figs_q7\\test_regular\n"
     ]
    }
   ],
   "source": [
    "# --- Q7 · evaluate baseline LR models on test set ---------------------------\n",
    "ART_DIR = Path(\"artifacts\")\n",
    "TEST_CSV = Path(\"../ift6758/data/milestone2/baseline_general_test.csv\")  # adjust if needed\n",
    "OUT_DIR  = Path(\"figs_q7/test_regular\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEED = 42\n",
    "\n",
    "# -------- plotting helpers (same shapes as your q2/q6)\n",
    "def roc_curve_pts(y_true, y_prob):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    return fpr, tpr\n",
    "\n",
    "def compute_goalrate_vs_percentile(y_true, y_prob, n_bins=100):\n",
    "    y = np.asarray(y_true); p = np.asarray(y_prob)\n",
    "    x_percentiles = np.arange(100, 0, -1)\n",
    "    rates = np.full(n_bins, np.nan, dtype=float)\n",
    "    for i, pct in enumerate(x_percentiles):\n",
    "        hi = np.quantile(p, pct/100.0, method=\"linear\")\n",
    "        lo = np.quantile(p, max(pct-1, 0)/100.0, method=\"linear\")\n",
    "        mask = (p > hi) & (p > lo) if pct > 1 else (p <= hi) & (p >= lo)\n",
    "        if mask.sum() > 0: rates[i] = y[mask].mean()\n",
    "    return x_percentiles, rates\n",
    "\n",
    "def compute_cum_goals_vs_percentile(y_true, y_prob, n_bins=100):\n",
    "    y = np.asarray(y_true); p = np.asarray(y_prob)\n",
    "    order = np.argsort(-p)               # high -> low\n",
    "    y_sorted = y[order]\n",
    "    cum_goals = np.cumsum(y_sorted)\n",
    "    total_goals = max(1, y.sum())\n",
    "    x_percentiles = np.arange(100, 0, -1)\n",
    "    n = len(y)\n",
    "    curve = np.zeros_like(x_percentiles, dtype=float)\n",
    "    for i, pct in enumerate(x_percentiles):\n",
    "        k = max(1, int(np.floor(pct/100.0 * n)))\n",
    "        curve[i] = cum_goals[k-1] / total_goals\n",
    "    return x_percentiles, curve\n",
    "\n",
    "def plot_roc(ax, y_true, curves):\n",
    "    ax.plot([0,1],[0,1], linestyle=\"--\", label=\"chance (45°)\")\n",
    "    for label, probs in curves.items():\n",
    "        fpr, tpr = roc_curve_pts(y_true, probs)\n",
    "        auc = roc_auc_score(y_true, probs)\n",
    "        ax.plot(fpr, tpr, label=f\"{label} (AUC={auc:.3f})\")\n",
    "    ax.set_title(\"ROC curve (test)\")\n",
    "    ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "def plot_goalrate(ax, y_true, curves):\n",
    "    for label, probs in curves.items():\n",
    "        x, y = compute_goalrate_vs_percentile(y_true, probs)\n",
    "        ax.plot(x, y, label=label)\n",
    "    ax.set_title(\"Goal Rate vs Model Percentile (test)\")\n",
    "    ax.set_xlabel(\"Shot probability model percentile (high→low)\")\n",
    "    ax.set_ylabel(\"Goals / Shots\"); ax.invert_xaxis(); ax.legend()\n",
    "\n",
    "def plot_cum_goals(ax, y_true, curves):\n",
    "    for label, probs in curves.items():\n",
    "        x, y = compute_cum_goals_vs_percentile(y_true, probs)\n",
    "        ax.plot(x, y, label=label)\n",
    "    ax.set_title(\"Cumulative % of Goals vs Percentile (test)\")\n",
    "    ax.set_xlabel(\"Shot probability model percentile (high→low)\")\n",
    "    ax.set_ylabel(\"Proportion of goals\"); ax.invert_xaxis(); ax.legend(loc=\"lower right\")\n",
    "\n",
    "def plot_calibration(ax, y_true, curves, n_bins=10):\n",
    "    from sklearn.calibration import CalibrationDisplay\n",
    "    for label, probs in curves.items():\n",
    "        CalibrationDisplay.from_predictions(y_true, probs, n_bins=n_bins, name=label, ax=ax)\n",
    "    ax.set_title(\"Reliability (Calibration) — test\")\n",
    "    ax.set_xlabel(\"Predicted probability\"); ax.set_ylabel(\"Observed frequency\")\n",
    "\n",
    "# -------- load test data\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "assert {\"distance_from_net\",\"shot_angle\",\"is_goal\"}.issubset(df_test.columns), \"missing baseline columns in test.csv\"\n",
    "y_test = df_test[\"is_goal\"].values\n",
    "\n",
    "# -------- load baseline artifacts and evaluate\n",
    "spec = {\n",
    "    \"lr-distance\": (ART_DIR/\"lr-distance.joblib\", [\"distance_from_net\"]),\n",
    "    \"lr-angle\":    (ART_DIR/\"lr-angle.joblib\",    [\"shot_angle\"]),\n",
    "    \"lr-both\":     (ART_DIR/\"lr-both.joblib\",     [\"distance_from_net\",\"shot_angle\"]),\n",
    "}\n",
    "\n",
    "curves = {}\n",
    "rows = []\n",
    "for name, (path, cols) in spec.items():\n",
    "    model = joblib.load(path)\n",
    "    X = df_test[cols].copy()\n",
    "    # predict\n",
    "    t0 = time.time()\n",
    "    prob = model.predict_proba(X)[:,1]\n",
    "    dt  = time.time() - t0\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    ap  = average_precision_score(y_test, prob)\n",
    "    b   = brier_score_loss(y_test, prob)\n",
    "    ll  = log_loss(y_test, prob, labels=[0,1])\n",
    "    rows.append((name, auc, ap, b, ll, dt))\n",
    "    curves[name] = prob\n",
    "\n",
    "# add random baseline\n",
    "curves[\"random\"] = np.random.RandomState(SEED).rand(len(y_test))\n",
    "\n",
    "# -------- print metrics table\n",
    "print(\"=== Baseline LR models on TEST ===\")\n",
    "for r in rows:\n",
    "    print(f\"{r[0]:<12} AUC={r[1]:.4f}  PR-AUC={r[2]:.4f}  Brier={r[3]:.4f}  LogLoss={r[4]:.4f}  time={r[5]:.3f}s\")\n",
    "\n",
    "# -------- save the four figures (baselines only for now)\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_roc(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_roc_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_goalrate(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_goalrate_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_cum_goals(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_cum_goals_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_calibration(ax, y_test, curves, n_bins=10)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_calibration_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "print(f\"\\nfigs written to: {OUT_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc5045",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Models on Playoffs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1078eb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline LR models on TEST ===\n",
      "lr-distance  AUC=0.6758  PR-AUC=0.1478  Brier=0.0766  LogLoss=0.2826  time=0.003s\n",
      "lr-angle     AUC=0.5674  PR-AUC=0.1104  Brier=0.0786  LogLoss=0.2923  time=0.001s\n",
      "lr-both      AUC=0.6957  PR-AUC=0.1643  Brier=0.0759  LogLoss=0.2783  time=0.002s\n",
      "\n",
      "figs written to: C:\\Users\\Gazal\\Documents\\Masters_Fall_2025\\Studies\\IFT 6758\\Projects\\Project_1 NHL\\Milestone_2\\data-science-code\\milestone2\\figs_q7\\test_regular\n"
     ]
    }
   ],
   "source": [
    "TEST_CSV = Path(\"../ift6758/data/milestone2/baseline_playoff_test.csv\")  # adjust if needed\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "assert {\"distance_from_net\",\"shot_angle\",\"is_goal\"}.issubset(df_test.columns), \"missing baseline columns in test.csv\"\n",
    "y_test = df_test[\"is_goal\"].values\n",
    "\n",
    "curves = {}\n",
    "rows = []\n",
    "for name, (path, cols) in spec.items():\n",
    "    model = joblib.load(path)\n",
    "    X = df_test[cols].copy()\n",
    "    # predict\n",
    "    t0 = time.time()\n",
    "    prob = model.predict_proba(X)[:,1]\n",
    "    dt  = time.time() - t0\n",
    "    auc = roc_auc_score(y_test, prob)\n",
    "    ap  = average_precision_score(y_test, prob)\n",
    "    b   = brier_score_loss(y_test, prob)\n",
    "    ll  = log_loss(y_test, prob, labels=[0,1])\n",
    "    rows.append((name, auc, ap, b, ll, dt))\n",
    "    curves[name] = prob\n",
    "\n",
    "# add random baseline\n",
    "curves[\"random\"] = np.random.RandomState(SEED).rand(len(y_test))\n",
    "\n",
    "# -------- print metrics table\n",
    "print(\"=== Baseline LR models on TEST ===\")\n",
    "for r in rows:\n",
    "    print(f\"{r[0]:<12} AUC={r[1]:.4f}  PR-AUC={r[2]:.4f}  Brier={r[3]:.4f}  LogLoss={r[4]:.4f}  time={r[5]:.3f}s\")\n",
    "\n",
    "# -------- save the four figures (baselines only for now)\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_roc(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_roc_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_goalrate(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_goalrate_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_cum_goals(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_cum_goals_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_calibration(ax, y_test, curves, n_bins=10)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_calibration_baselines.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "print(f\"\\nfigs written to: {OUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d73d9a",
   "metadata": {},
   "source": [
    "# Evaluate the Best Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9434a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV = Path(\"../ift6758/data/milestone2/advanced_general_test.csv\")  # adjust if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076d556",
   "metadata": {},
   "source": [
    "## Evaluat the Best Catboost Model on Regular Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c899db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Q7 · add best Q6 CatBoost (+ Platt calibration) on TEST -----------------\n",
    "# ---- locked-17 feature recipe (must match training)\n",
    "BASE = [\"distance_from_net\",\"rebound\",\"period\",\"last_event_distance\",\n",
    "        \"shot_angle\",\"shot_type\",\"period_time_seconds\"]\n",
    "RAW  = [\"time_since_last_event\",\"angle_change\",\"event_speed\",\"last_event_type\"]\n",
    "DERIVED = [\"log_distance\",\"abs_angle\",\"cos_angle\",\"dist_x_abs_angle\",\"rush\",\"big_turn\"]\n",
    "FEATURES = BASE + RAW + DERIVED\n",
    "CAT_COLS = [\"shot_type\",\"last_event_type\",\"period\"]\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"rebound\"] = out[\"rebound\"].astype(float)\n",
    "    out[\"log_distance\"] = np.log1p(out[\"distance_from_net\"])\n",
    "    out[\"abs_angle\"] = np.abs(out[\"shot_angle\"])\n",
    "    out[\"cos_angle\"] = np.cos(np.deg2rad(out[\"shot_angle\"]))\n",
    "    out[\"dist_x_abs_angle\"] = out[\"distance_from_net\"] * out[\"abs_angle\"]\n",
    "    out[\"rush\"] = (out[\"time_since_last_event\"] <= 2).astype(float)\n",
    "    out[\"big_turn\"] = (out[\"angle_change\"] >= 30).astype(float)\n",
    "    return out\n",
    "\n",
    "def make_pool(X: pd.DataFrame, y=None):\n",
    "    # impute categoricals like in training\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    for c in CAT_COLS:\n",
    "        if c in X.columns:\n",
    "            X.loc[:, c] = imputer.fit_transform(X[[c]])[:,0]\n",
    "    cat_idx = [X.columns.get_loc(c) for c in CAT_COLS if c in X.columns]\n",
    "    return Pool(X, label=y, cat_features=cat_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "842003c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q6 CatBoost CAL]  AUC=0.8737  PR-AUC=0.5696  Brier=0.0623  LogLoss=0.2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figs written to: C:\\Users\\Gazal\\Documents\\Masters_Fall_2025\\Studies\\IFT 6758\\Projects\\Project_1 NHL\\Milestone_2\\data-science-code\\milestone2\\figs_q7\\test_regular\n"
     ]
    }
   ],
   "source": [
    "# ---- load test\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "df_test = add_features(df_test)\n",
    "missing = set(FEATURES + [\"is_goal\"]) - set(df_test.columns)\n",
    "assert not missing, f\"test.csv missing columns: {missing}\"\n",
    "\n",
    "X_test = df_test[FEATURES].copy()\n",
    "y_test = df_test[\"is_goal\"].values\n",
    "\n",
    "# ---- load CatBoost + Platt\n",
    "cb_path = Path(\"q6_catboost_final.cbm\")\n",
    "platt_path = Path(\"q6_platt.joblib\")\n",
    "\n",
    "cb = CatBoostClassifier()\n",
    "cb.load_model(str(cb_path))\n",
    "\n",
    "pool_test = make_pool(X_test, y_test)\n",
    "p_raw = cb.predict_proba(pool_test)[:,1]\n",
    "\n",
    "try:\n",
    "    platt = joblib.load(platt_path)\n",
    "    p_cat = platt.predict_proba(p_raw.reshape(-1,1))[:,1]\n",
    "    cal_used = True\n",
    "except Exception:\n",
    "    p_cat = p_raw\n",
    "    cal_used = False\n",
    "\n",
    "# ---- metrics\n",
    "auc  = roc_auc_score(y_test, p_cat)\n",
    "ap   = average_precision_score(y_test, p_cat)\n",
    "brier = brier_score_loss(y_test, p_cat)\n",
    "ll    = log_loss(y_test, p_cat, labels=[0,1])\n",
    "\n",
    "print(f\"[Q6 CatBoost {'CAL' if cal_used else 'RAW'}]  AUC={auc:.4f}  PR-AUC={ap:.4f}  Brier={brier:.4f}  LogLoss={ll:.4f}\")\n",
    "\n",
    "# ---- also load the 3 LR baselines to make combined 4-curve plots\n",
    "spec = {\n",
    "    \"lr-distance\": (ART_DIR/\"lr-distance.joblib\", [\"distance_from_net\"]),\n",
    "    \"lr-angle\":    (ART_DIR/\"lr-angle.joblib\",    [\"shot_angle\"]),\n",
    "    \"lr-both\":     (ART_DIR/\"lr-both.joblib\",     [\"distance_from_net\",\"shot_angle\"]),\n",
    "}\n",
    "curves = {(\"catboost (calibrated)\" if cal_used else \"catboost (raw)\"): p_cat}\n",
    "for name, (path, cols) in spec.items():\n",
    "    m = joblib.load(path)\n",
    "    curves[name] = m.predict_proba(df_test[cols])[:,1]\n",
    "curves[\"random\"] = np.random.RandomState(42).rand(len(y_test))\n",
    "\n",
    "# ---- save the 4 figures (now: catboost + 3 LR + random)\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_roc(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_roc_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_goalrate(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_goalrate_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_cum_goals(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_cum_goals_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_calibration(ax, y_test, curves, n_bins=10)\n",
    "plt.savefig(OUT_DIR/\"q7_general_test_calibration_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "print(f\"figs written to: {OUT_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fb90e",
   "metadata": {},
   "source": [
    "## Evaluat the Best Catboost Model on Playoffs Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c52db29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV = Path(\"../ift6758/data/milestone2/advanced_playoff_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8bf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q6 CatBoost CAL]  AUC=0.8510  PR-AUC=0.4922  Brier=0.0598  LogLoss=0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Gazal\\anaconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figs written to: C:\\Users\\Gazal\\Documents\\Masters_Fall_2025\\Studies\\IFT 6758\\Projects\\Project_1 NHL\\Milestone_2\\data-science-code\\milestone2\\figs_q7\\test_regular\n"
     ]
    }
   ],
   "source": [
    "# ---- load test\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "df_test = add_features(df_test)\n",
    "missing = set(FEATURES + [\"is_goal\"]) - set(df_test.columns)\n",
    "assert not missing, f\"test.csv missing columns: {missing}\"\n",
    "\n",
    "X_test = df_test[FEATURES].copy()\n",
    "y_test = df_test[\"is_goal\"].values\n",
    "\n",
    "# ---- load CatBoost + Platt\n",
    "cb_path = Path(\"q6_catboost_final.cbm\")\n",
    "platt_path = Path(\"q6_platt.joblib\")\n",
    "\n",
    "cb = CatBoostClassifier()\n",
    "cb.load_model(str(cb_path))\n",
    "\n",
    "pool_test = make_pool(X_test, y_test)\n",
    "p_raw = cb.predict_proba(pool_test)[:,1]\n",
    "\n",
    "try:\n",
    "    platt = joblib.load(platt_path)\n",
    "    p_cat = platt.predict_proba(p_raw.reshape(-1,1))[:,1]\n",
    "    cal_used = True\n",
    "except Exception:\n",
    "    p_cat = p_raw\n",
    "    cal_used = False\n",
    "\n",
    "# ---- metrics\n",
    "auc  = roc_auc_score(y_test, p_cat)\n",
    "ap   = average_precision_score(y_test, p_cat)\n",
    "brier = brier_score_loss(y_test, p_cat)\n",
    "ll    = log_loss(y_test, p_cat, labels=[0,1])\n",
    "\n",
    "print(f\"[Q6 CatBoost {'CAL' if cal_used else 'RAW'}]  AUC={auc:.4f}  PR-AUC={ap:.4f}  Brier={brier:.4f}  LogLoss={ll:.4f}\")\n",
    "\n",
    "# ---- also load the 3 LR baselines to make combined 4-curve plots\n",
    "spec = {\n",
    "    \"lr-distance\": (ART_DIR/\"lr-distance.joblib\", [\"distance_from_net\"]),\n",
    "    \"lr-angle\":    (ART_DIR/\"lr-angle.joblib\",    [\"shot_angle\"]),\n",
    "    \"lr-both\":     (ART_DIR/\"lr-both.joblib\",     [\"distance_from_net\",\"shot_angle\"]),\n",
    "}\n",
    "curves = {(\"catboost (calibrated)\" if cal_used else \"catboost (raw)\"): p_cat}\n",
    "for name, (path, cols) in spec.items():\n",
    "    m = joblib.load(path)\n",
    "    curves[name] = m.predict_proba(df_test[cols])[:,1]\n",
    "curves[\"random\"] = np.random.RandomState(42).rand(len(y_test))\n",
    "\n",
    "# ---- save the 4 figures (now: catboost + 3 LR + random)\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_roc(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_roc_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_goalrate(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_goalrate_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_cum_goals(ax, y_test, curves)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_cum_goals_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(7,5)); ax=plt.gca(); plot_calibration(ax, y_test, curves, n_bins=10)\n",
    "plt.savefig(OUT_DIR/\"q7_playoff_test_calibration_core4.png\", dpi=160, bbox_inches=\"tight\"); plt.close()\n",
    "\n",
    "print(f\"figs written to: {OUT_DIR.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
